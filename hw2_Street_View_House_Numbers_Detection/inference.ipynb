{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nW4BN-FEHAn"
      },
      "source": [
        "# STEP 0: Use GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3rG-rjUEKyZ",
        "outputId": "65a04dda-553c-4f80-d481-20ab6423763e"
      },
      "source": [
        "# Make sure you use the Colab GPU to run the testing phase\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h84u9Y9zAv49",
        "outputId": "6b3e5cd3-62fb-4eea-d4d2-e1f715512e4b"
      },
      "source": [
        "# Show the GPU info\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 24 16:23:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    28W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o31NmbOe89Gc"
      },
      "source": [
        "# STEP 1: Git clone your project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hteyN2COWmz",
        "outputId": "d9259570-5ee0-4283-f3ee-5851d93f0e7c"
      },
      "source": [
        "# Git clone your project\n",
        "\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 21768, done.\u001b[K\n",
            "remote: Total 21768 (delta 0), reused 0 (delta 0), pack-reused 21768\u001b[K\n",
            "Receiving objects: 100% (21768/21768), 25.18 MiB | 22.17 MiB/s, done.\n",
            "Resolving deltas: 100% (15290/15290), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmYxECpc9YBU"
      },
      "source": [
        "# STEP 2: Install your requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaYZdp6wPq-I",
        "outputId": "3192fe4a-2f86-4ffc-e5ac-0873605e0bf6"
      },
      "source": [
        "# Install your requirments (torch, mmcv, ...)\n",
        "# It is recommended that you wirte the requirements.txt file in your project.\n",
        "\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install mmcv-full\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "!pip install googledrivedownloader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmdetection\n",
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.3.17.tar.gz (390 kB)\n",
            "\u001b[K     |████████████████████████████████| 390 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.6)\n",
            "Building wheels for collected packages: mmcv-full\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl size=44399268 sha256=8072579c3b5147f8839950730337ee679a79f03a64e5ce86cf5b93ac45bef537\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/63/2c/49cc449e4a860b364c49c0b77d2275cb012f625d7c9203e444\n",
            "Successfully built mmcv-full\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.3.17 yapf-0.31.0\n",
            "Obtaining file:///content/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (2.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (2.8.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.18.1) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.18.1) (57.4.0)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=b1a6aebe460db1aacb0a2b9a7f2db3d26b44a5ccb5da12fc6f61e4f4a7a4c9d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.18.1 terminaltables-3.1.0\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4M1nNaTRgQm",
        "outputId": "cb0a8924-4a76-4dd4-f266-f16bc5ffe07f"
      },
      "source": [
        "# Import your package and check the version\n",
        "\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "\n",
        "# You must import the below 5 packages \n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111 True\n",
            "2.18.1\n",
            "11.1\n",
            "GCC 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXA_BqhN9u7S"
      },
      "source": [
        "# STEP 3: Wget testing data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCmc4eTGQ-sz",
        "outputId": "645fc898-9b5c-4ba3-cbef-7bd98788ea37"
      },
      "source": [
        "# 1. Download the testing data\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1Fm-avdeNgzhPxhvia0iw9yZzcoOggy7I',\n",
        "                                    dest_path='./test.zip',\n",
        "                                    unzip=True)\n",
        "\n",
        "# 2. Read the image_name and put them into the list\n",
        "# You need to modify the path to fit your test_folder\n",
        "data_listdir = os.listdir(\"/content/mmdetection/test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1Fm-avdeNgzhPxhvia0iw9yZzcoOggy7I into ./test.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba1gPW5PGGjA"
      },
      "source": [
        "# STEP 4: Run inferene and bench mark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTs4phq2W8zG",
        "outputId": "1cd648a3-3fcc-406e-da44-1bf3d93a456c"
      },
      "source": [
        "# from google.colab import drive\n",
        "# from google.colab import files\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 1. Load your model and weights\n",
        "config = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/cascade_rcnn_r50_fpn_1x_coco_SVHN/cascade_rcnn_r50_fpn_1x_coco_SVHN.py'\n",
        "checkpoint = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/cascade_rcnn_r50_fpn_1x_coco_SVHN/epoch_12.pth'\n",
        "# config = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/faster_rcnn_r50_fpn_1x_coco_SVHN/faster_rcnn_r50_fpn_1x_coco_SVHN.py'\n",
        "# checkpoint = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/faster_rcnn_r50_fpn_1x_coco_SVHN/epoch_12.pth'\n",
        "# config = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/yolov3_d53_mstrain-416_273e_coco_SVHN/yolov3_d53_mstrain-416_273e_coco_SVHN.py'\n",
        "# checkpoint = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/yolov3_d53_mstrain-416_273e_coco_SVHN/epoch_273.pth'\n",
        "# config = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN.py'\n",
        "# checkpoint = '/content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN/epoch_25.pth'\n",
        "\n",
        "# 2. Initialize the model\n",
        "model = init_detector(config, checkpoint, device='cuda:0')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. \n",
            "  f'The arguments `{ori_name}` in BaseTransformerLayer '\n",
            "/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. \n",
            "  f'The arguments `{ori_name}` in BaseTransformerLayer '\n",
            "/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. \n",
            "  f'The arguments `{ori_name}` in BaseTransformerLayer '\n",
            "/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) \n",
            "  warnings.warn('The arguments `dropout` in MultiheadAttention '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN/epoch_25.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2CL2iZbK1vc"
      },
      "source": [
        "### Please **screenshot** this cell, including the code and the output (your inference time), and put it into your report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP3Cp5vYXVYq",
        "outputId": "b795e1be-eadc-40fa-918e-5d65e733c5e4"
      },
      "source": [
        "# Test your inference time\n",
        "TEST_IMAGE_NUMBER = 100 # This number is fixed.\n",
        "test_img_list = []\n",
        "\n",
        "# Read image (Be careful with the image order)\n",
        "data_listdir.sort(key = lambda x: int(x[:-4]))\n",
        "for img_name in data_listdir[:TEST_IMAGE_NUMBER]:\n",
        "  img_path = os.path.join(\"/content/mmdetection/test\", img_name)\n",
        "  img = cv2.imread(img_path)\n",
        "  test_img_list.append(img)\n",
        "\n",
        "start_time = time.time()\n",
        "for img in tqdm(test_img_list):\n",
        "    # your model prediction\n",
        "    pred = inference_detector(model, img)\n",
        "\n",
        "end_time  = time.time()\n",
        "print(\"\\nInference time per image: \", (end_time - start_time) / len(test_img_list))\n",
        "\n",
        "# Remember to screenshot!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]/content/mmdetection/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
            "  'data pipeline in your config file.', UserWarning)\n",
            "/content/mmdetection/mmdet/models/utils/positional_encoding.py:81: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/content/mmdetection/mmdet/models/utils/transformer.py:883: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = temperature**(2 * (dim_t // 2) / num_pos_feats)\n",
            "/content/mmdetection/mmdet/models/dense_heads/detr_head.py:666: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  bbox_index = indexes // self.num_classes\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inference time per image:  0.3662575626373291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxMYbthMjdQ"
      },
      "source": [
        "# STEP 5: Generate answer.json for submission on Codalab\n",
        "The answer.json has the same format as [COCO dataset results](https://cocodataset.org/#format-results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArOVFKCb0dgZ"
      },
      "source": [
        "### Pseudo code for generating submission file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVr_Mls8NBe6"
      },
      "source": [
        "# Generate answer files to submit in Codalab competitions\n",
        "\n",
        "# Run prediction script first\n",
        "# Reference: https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html\n",
        "# Configs and trained models could be found here: https://drive.google.com/drive/folders/1KfcGQ5EQSm6eZsDoZp28G_f2a2KlwTTB?usp=sharing\n",
        "\n",
        "!./tools/dist_test.sh \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/cascade_rcnn_r50_fpn_1x_coco_SVHN/cascade_rcnn_r50_fpn_1x_coco_SVHN.py \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/cascade_rcnn_r50_fpn_1x_coco_SVHN/epoch_12.pth \\\n",
        "    1 \\\n",
        "    --format-only \\\n",
        "    --options \"jsonfile_prefix=./cascade_rnn_inference\"\n",
        "\n",
        "!./tools/dist_test.sh \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/faster_rcnn_r50_fpn_1x_coco_SVHN/faster_rcnn_r50_fpn_1x_coco_SVHN.py \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/faster_rcnn_r50_fpn_1x_coco_SVHN/epoch_12.pth \\\n",
        "    1 \\\n",
        "    --format-only \\\n",
        "    --options \"jsonfile_prefix=./faster_rcnn_inference\"\n",
        "\n",
        "!./tools/dist_test.sh \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/yolov3_d53_mstrain-416_273e_coco_SVHN/yolov3_d53_mstrain-416_273e_coco_SVHN.py \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/yolov3_d53_mstrain-416_273e_coco_SVHN/epoch_273.pth \\\n",
        "    1 \\\n",
        "    --format-only \\\n",
        "    --options \"jsonfile_prefix=./yolov3_inference\"\n",
        "\n",
        "!./tools/dist_test.sh \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN.py \\\n",
        "    /content/drive/MyDrive/Course/VRDL_2021au/HW2/work_dirs/deformable_detr_twostage_refine_r50_16x2_50e_coco_SVHN/epoch_25.pth \\\n",
        "    1 \\\n",
        "    --format-only \\\n",
        "    --options \"jsonfile_prefix=./deformable_detr_inference\"\n",
        "\n",
        "# Then run the generate_anwer.py to submit the results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}